services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      # The following two are optional when using `gpus: all`, but harmless:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Keep models warm for interactive use (default ~5m). Tweak to taste:
      - OLLAMA_KEEP_ALIVE=10m
    volumes:
      - ./ollama:/root/.ollama        # models + state (lives on your Windows filesystem)
    gpus: all                          # <-- enable NVIDIA GPU in Compose
    restart: unless-stopped

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    depends_on:
      - ollama
      - searxng
      - mcp-time
    ports:
      - "3000:8080"                   # Web UI: http://localhost:3000
    environment:
      # Authentication and user management
      - WEBUI_AUTH=false
      - ENABLE_SIGNUP=true
      - SINGLE_USER_MODE=true
      - DEFAULT_ADMIN_USERNAME=${WEBUI_ADMIN_USER}
      - DEFAULT_ADMIN_PASSWORD=${WEBUI_ADMIN_PASS}
      - WEBUI_NAME=Birge WebUI
      # Ollama backend connection
      - OLLAMA_BASE_URL=http://ollama:11434
      - OPENAI_API_BASE=http://ollama:11434/v1
      - OPENAI_API_KEY=dummy
      # Make this the default visible model in the selector on first launch (optional)
      - DEFAULT_MODELS=llama3.1:8b
      # Tool servers
      - ENABLE_DIRECT_CONNECTIONS=true
      - TOOL_SERVER_CONNECTIONS=[
          {
            "url":"http://mcpo-time:8001",
            "path":"/openapi.json",
            "auth_type":"none",
            "info":{
              "name":"mcp-time",
              "description":"MCP time server via mcpo"
            }
          }
        ]
      # SearXNG via a tool/extension inside WebUI
      - SEARXNG_URL=http://searxng:8080
      # Set to false to disable persistent config to reset to defaults
      - ENABLE_PERSISTENT_CONFIG=true
    volumes:
      - ./openwebui:/app/backend/data
    restart: unless-stopped

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "8080:8080"                   # SearXNG web interface: http://localhost:8080
    environment:
      - SEARXNG_BASE_URL=http://localhost:8080/
      - UWSGI_WORKERS=2
    volumes:
      - ./config:/etc/searxng/        # persist config (matches: -v "./config/:/etc/searxng/")
      - ./data:/var/cache/searxng/    # persist cache/data (matches: -v "./data/:/var/cache/searxng/")
    restart: unless-stopped

  # MCP services via mcpo
  mcp-time:
    image: ghcr.io/open-webui/mcpo:main
    container_name: mcpo-time                # MCP time server
    command: [
      "mcpo","--host","0.0.0.0",
      "--port","8001",
      "--",
      "uvx","mcp-server-time",
      "--local-timezone=America/New_York"
    ]
    restart: unless-stopped

# networks:
#   default:
#     name: local-llm-net
